---
layout: post
title:  "An Automated Approach for Large-Scale Lexical Substitution"
---
This website contains new large-scale datasets for the task of lexical substitution. Each instance in the datasets contains a target word in its context, associated with a silver list of possible substitutes. The automated procedure to obtain the datasets is described in the <a href="https://www.diag.uniroma1.it/navigli/pubs/IJCAI_2021_Lacerraetal.pdf" target='_blank'>ALaSca</a> paper. 

## Abstract
The lexical substitution task aims at finding suitable replacements for words in context. The paucity of annotated data has forced researchers to apply mainly unsupervised approaches, limiting the applicability of large pre-trained models and thus hampering the potential benefits of supervised approaches to the task. We mitigate this issue by proposing ALaSca, a novel approach to automatically creating large-scale datasets for English lexical substitution. ALaSca allows examples to be produced for potentially any word in a language vocabulary and to cover most of the meanings it lists. Thanks to this, we can unleash the full potential of neural architectures and finetune them on the lexical substitution task. Indeed, when using our data, a transformer-based model  performs substantially better than when using manually-annotated data only.   
## Datasets
The datasets used in the paper can be downloaded <a href="https://github.com/SapienzaNLP/alasca/raw/main/docs/assets/alasca_dataset.zip" download target="_blank">here</a>. The .zip folder contains the following files:

```bash 
alasca_train.tsv            # the dataset (alasca_t) built with the procedure described in our paper.
alasca_coinco_train.tsv     # alasca_t concatenated with the training split of CoInCo.
alasca_twsi_train.tsv       # alasca_t concatenated with the training split of TWSI.
alasca_with_gold_train.tsv  # alasca_t concatenated with the training splits of CoInCo and TWSI.
coinco_train.tsv            # the training split of CoInCo.
twsi_train.tsv              # the training split of TWSI.
coinco_twsi_train.tsv       # the training splits of CoInCo and TWSI.
coinco_twsi_dev.tsv         # dev splits of CoInCo and TWSI.
lst_test.tsv                # test set (LST).
```
Each dataset has the same format.
Consider, as example, a row from ```alasca_train.tsv```, i.e. 


```arrest.VERB     1498    5       All of the protesters were arrested .   apprehend capture catch jail convict detain charge confront imprison    detain::10```

It is formatted as:
```bash
lexeme \t instance_id \t target_index \t sentence \t mask \t gold
```
where:

```lexeme``` represents the target word and is formatted as ```{lemma}.{pos}```, 

```instance_id``` is an integer that identifies the instance, i.e. the triple (lexeme, target index, sentence)

```target_index``` is an integer that represents the index of the target word in the sentence (starting from 0).

```sentence``` is the context where the target appears, space-separated.

```mask``` is the set of substitutes across instances for the given target lexeme. Space are replaced with underscores.

```gold``` is a space-separated list of ```word::score``` elements, where each element is a possible substitute for the target in context with its relative score. Also in this case, spaces inside the words have been replaced with underscores. The scores indicate how suitable a substitute is for the given context: the higher the score, the better the substitute.



## Supplementary Material
In the [supplementary material](https://raw.githubusercontent.com/caterinaLacerra/alasca/master/docs/assets/supplementary_alasca.pdf) we provide the results for each tuned value of similarity threshold.


## Reference
Please cite our work as 

'''{}'''

## Authors
<div style="display:inline-block;vertical-align:middle;">
<img class="img" src="https://raw.githubusercontent.com/caterinaLacerra/alasca/master/docs/_images/totem_cate.png" width="60px">
</div>
<div style="display:inline-block;vertical-align:middle;">  
<p class="content-holder">
  <a href="https://caterinalacerra.github.io/" target='_blank'>Caterina Lacerra</a> (contact author)<br/>
  PhD Student @ Sapienza University of Rome<br/>
  lacerra [at] uniroma1.it
</p>
</div><br/>

<div style="display:inline-block;vertical-align:middle;">
<img class="img" src="https://raw.githubusercontent.com/caterinaLacerra/alasca/master/docs/_images/totem_tommaso.png" width="60px">
 </div>
<div style="display:inline-block;vertical-align:middle;">
<p class="content-holder">
  <a href="https://pasinit.github.io/" target='_blank'>Tommaso Pasini</a><br/>
  Post-Doctoral Research Fellow @ University of Copenhagen<br/>
  tommaso.pasini [at] di.ku.dk
</p>
</div><br/>


<div style="display:inline-block;vertical-align:middle;">
<img class="img" src="https://raw.githubusercontent.com/caterinaLacerra/alasca/master/docs/_images/totem_rocco.png" width="60px">
</div>
<div style="display:inline-block;vertical-align:middle;">
  <p class="content-holder">
  <a href="https://twitter.com/rocco_tri?lang=en" target='_blank'>Rocco Tripodi</a><br/>
  Assistant Professor @ University of Bologna<br/>
  rocco.tripodi [at] unibo.it 
</p>
</div><br/>

<div  style="display:inline-block;vertical-align:middle;">
<img class="img" src="https://raw.githubusercontent.com/caterinaLacerra/alasca/master/docs/_images/totem_prof.png" width="60px">
</div>

<div style="display:inline-block;vertical-align:middle;">
  <p class="content-holder">
  <a href="http://www.users.di.uniroma1.it/~navigli/" target='_blank'>Roberto Navigli</a><br/>
  Full Professor @ Sapienza<br/>
  navigli [at] uniroma1.it
</p>
</div><br/>


### Acknowledgements


<div  style="display:inline-block;vertical-align:middle;">
<img class="img" src="https://raw.githubusercontent.com/caterinaLacerra/alasca/master/docs/_images/erc_logo.png" width="40px">
</div>

<div style="display:inline-block;vertical-align:middle;">
  <p class="content-holder">
    The authors gratefully acknowledge the support of the ERC Consolidator Grant<br/>MOUSSE No. 726487 under the European Union’s Horizon 2020 research and<br/> innovation programme.
</p>
</div>

This work was supported in part by the MIUR under grant “Dipartimenti di eccellenza 2018-2022” of the Department of Computer Science of the Sapienza University of Rome.

### License
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
